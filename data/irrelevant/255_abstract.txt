The invention discloses a speech separation method of a deep stacked residual network The method includes the steps manufacturing of a speech signal data set feature extraction of a speech signalextraction of a melfrequency cepstral coefficient an Amplitude Modulation Spectrogram a Gammatone feature Relative Spectral TransformPerceptual Linear Prediction and a shorttime Fourier transform amplitude spectrum of each frame of the speech signal building of the deep stacked residual network manufacturing of a learning label manufacturing of a loss function training of a deep stackedresidual network model According to separated speech higher speech quality and speech intelligibility can be acquired in the acoustic environment with low signal to noise ratio According to the method a separation model with good robustness can be acquired without repetitive iteration at the training stage of the model the generalization ability of the model is high and good performances canbe achieved in unmatched noise environments